{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "module_path = os.path.join(module_path, 'scripts')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipsharm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vipsharm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "from bs4 import NavigableString, BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import string\n",
    "\n",
    "from utils.config import config\n",
    "from utils.logger.logger import loggerCreator\n",
    "\n",
    "## ePI Modules\n",
    "from parse.rulebook.rulebook import StyleRulesDictionary\n",
    "\n",
    "from parse.extractor.parser import parserExtractor\n",
    "from match.matchDocument.matchDocument import MatchDocument\n",
    "from documentAnnotation.documentAnnotation import DocumentAnnotation\n",
    "from htmlDocTypePartitioner.partition import DocTypePartitioner\n",
    "from extractContentBetweenHeadings.dataBetweenHeadingsExtractor import DataBetweenHeadingsExtractor\n",
    "from fhirXmlGenerator.fhirXmlGenerator import FhirXmlGenerator\n",
    "#from fhirService.fhirService import FhirService\n",
    "from utils.logger.matchLogger import MatchLogger\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomString(N):\n",
    "    str_ = ''.join(random.choice(string.ascii_uppercase + string.digits \\\n",
    "            + string.ascii_lowercase) for _ in range(N))\n",
    "    return str_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Required Field for Parsing and Partition Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please ensure that your converted_html folder has html files in their specific language folders\n",
    "\n",
    "Example: If your language code is en, please ensure that all html files reside in the converted_html/en folder. If folder is not present, a folder not found exception will be thrown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ePILanguage = 'en'\n",
    "fileNameQrd = 'qrd_canonical_mode_CAP_NAP.csv'\n",
    "procedureType = 'CAP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ePILanguage = 'de'\n",
    "fileNameQrd = 'qrd_canonical_mode_CAP_NAP.csv'\n",
    "procedureType = 'CAP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ePILanguage = 'es'\n",
    "fileNameQrd = 'qrd_canonical_mode_CAP_NAP.csv'\n",
    "procedureType = 'CAP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulgarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ePILanguage = 'bg'\n",
    "fileNameQrd = 'qrd_canonical_mode_CAP_NAP.csv'\n",
    "procedureType = 'CAP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ePILanguage = 'el'\n",
    "fileNameQrd = 'qrd_canonical_mode_CAP_NAP.csv'\n",
    "procedureType = 'CAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Html Parsing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FolderNotFoundError(Exception):\n",
    "    pass\n",
    "\n",
    "## Generate input folder path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "module_path = os.path.join(module_path, 'data')\n",
    "module_path = os.path.join(module_path, 'converted_to_html')\n",
    "module_path = os.path.join(module_path, ePILanguage)\n",
    "\n",
    "## Generate output folder path\n",
    "output_json_path = module_path.replace('converted_to_html','outputJSON')\n",
    "\n",
    "\"\"\"\n",
    "    Check if input folder exists, else throw exception\n",
    "\"\"\"\n",
    "if(os.path.exists(module_path)):\n",
    "    filenames = glob.glob(os.path.join(module_path, '*.html'))\n",
    "    filenames.extend(glob.glob(os.path.join(module_path, '*.htm')))\n",
    "    \n",
    "    ## Create language specific folder in outputJSON folder if it doesn't exist\n",
    "    if(not os.path.exists(output_json_path)):\n",
    "        os.mkdir(output_json_path)\n",
    "    logger = loggerCreator('Parser_'+ getRandomString(1))\n",
    "    \n",
    "    styleRulesObj = StyleRulesDictionary(loggerCreator('Style Dictionary_'+ getRandomString(1)),\n",
    "                                     language = ePILanguage,\n",
    "                                     fileName = fileNameQrd,\n",
    "                                     procedureType = procedureType)\n",
    "\n",
    "    parserObj = parserExtractor(config, logger, styleRulesObj.styleRuleDict, \n",
    "                            styleRulesObj.styleFeatureKeyList, \n",
    "                            styleRulesObj.qrd_section_headings)\n",
    "\n",
    "    for input_filename in filenames:\n",
    "      #if(input_filename.find('Kalydeco II-86-PI-clean')!=-1):\n",
    "        output_filename = input_filename.replace('converted_to_html','outputJSON')\n",
    "        output_filename = output_filename.replace('.html','.json')\n",
    "        output_filename = output_filename.replace('.htm','.json')\n",
    "        print(input_filename, output_filename)\n",
    "        parserObj.createPIJsonFromHTML(input_filepath = input_filename,\n",
    "                                       output_filepath = output_filename,\n",
    "                                       img_base64_dict= parserObj.convertImgToBase64(input_filename),\n",
    "                                      )\n",
    "else:\n",
    "    raise FolderNotFoundError(module_path + \" not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styleRulesObj = StyleRulesDictionary(loggerCreator('Style Dictionary_'+ getRandomString(1)), \n",
    "                                     language = ePILanguage,\n",
    "                                     fileName = fileNameQrd,\n",
    "                                     procedureType = procedureType)\n",
    "\n",
    "path_json = os.path.join(os.path.abspath(os.path.join('..')), 'data', 'outputJSON', ePILanguage)\n",
    "\n",
    "partitionlogger = loggerCreator('Partition_'+ getRandomString(1))\n",
    "partitioner = DocTypePartitioner(partitionlogger)\n",
    "partitioner.partitionHtmls(styleRulesObj.qrd_section_headings, path_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedureType = 'CAP'\n",
    "languageCode = 'es'\n",
    "stopWordlanguage = 'spanish'\n",
    "fileNameQrd = 'qrd_canonical_mode_CAP_NAP.csv'\n",
    "fileNameMatchRuleBook = 'ruleDict.json'\n",
    "fileNameDocumentTypeNames = 'documentTypeNames.json'\n",
    "fileNameDoc = 'emea-combined-h-2494-es_ PROSPECTO.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SmPC\n",
    "documentNumber = 3\n",
    "docFilter = \"PROSPECTO.json\"\n",
    "stopWordFilterLen = 100\n",
    "start=0\n",
    "end=1\n",
    "isPackageLeaflet=True\n",
    "topHeadingsConsidered = 5\n",
    "bottomHeadingsConsidered = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " os.environ['APPLICATIONINSIGHTS_CONNECTION_STRING'] = \"InstrumentationKey=769acdf5-503c-43e6-9736-77925ec553f0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(os.path.abspath(os.path.join('..')),'utils','matchLog.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = MatchLogger(\"Matching Logger\",fileNameDoc, procedureType, languageCode, documentNumber, fileNameLog = os.path.join(os.path.abspath(os.path.join('..')), 'code','utils','matchLog.txt'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matchDocObj = MatchDocument(\n",
    "                 logger,\n",
    "                 procedureType,\n",
    "                 languageCode,\n",
    "                 documentNumber,\n",
    "                 fileNameDoc,\n",
    "                 fileNameQrd,\n",
    "                 fileNameMatchRuleBook,\n",
    "                 fileNameDocumentTypeNames,\n",
    "                 topHeadingsConsidered,\n",
    "                 bottomHeadingsConsidered,\n",
    "                 stopWordFilterLen,\n",
    "                 stopWordlanguage,\n",
    "                 isPackageLeaflet,\n",
    "                 'Kalydeco')\n",
    "df, coll = matchDocObj.matchHtmlHeaddingsWithQrd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Extraction Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractContentlogger = loggerCreator('ExtractContentBetween_'+ getRandomString(1))\n",
    "extractorObj = DataBetweenHeadingsExtractor(extractContentlogger, coll)\n",
    "dfExtractedHierRR = extractorObj.extractContentBetweenHeadings('Abilify-h-471-e_ PACKAGE LEAFLET.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Generation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlLogger = loggerCreator('XmlGeneration_'+ getRandomString(1))\n",
    "fhirXmlGeneratorObj = FhirXmlGenerator(xmlLogger)\n",
    "fhirXmlGeneratorObj.generateXml(dfExtractedHierRR,  'Abilify-h-471-e_ PACKAGE LEAFLET.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertCollectionToDataFrame(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAnnotationObj = DocumentAnnotation('Kalydeco II-86-PI-clean_SmPC.json','c270d6ccaf9e47e9b20b322e2383c4ba','https://spor-uat.azure-api.net/pms/api/v2/','df','coll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = documentAnnotationObj.processRegulatedAuthorizationForDoc(['EU/2/10/106/006','EU/2/09/098/001'])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Author Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Medicinal Product Definitions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAnnotationObj.processRegulatedAuthorizationForDoc(['EU/3/00/001','EU/1/97/039/003'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-To-End Flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDocuments(procedureType,\n",
    "                   languageCode,\n",
    "                   documentNumber,\n",
    "                   docFilter,\n",
    "                   fileNameQrd,\n",
    "                   fileNameMatchRuleBook,\n",
    "                   fileNameDocumentTypeNames,\n",
    "                   stopWordFilterLen=6,\n",
    "                   start=0,\n",
    "                   end=10,\n",
    "                   isPackageLeaflet=False,\n",
    "                   medName=None):\n",
    "\n",
    "    '''\n",
    "    This function was created to run the match function on multiple documents in automated fashion.\n",
    "    \n",
    "    '''\n",
    "    if documentNumber == 0:\n",
    "        topHeadingsConsidered=4\n",
    "        bottomHeadingsConsidered=6\n",
    "    elif documentNumber == 1:\n",
    "        topHeadingsConsidered=3\n",
    "        bottomHeadingsConsidered=5\n",
    "    elif documentNumber == 2:\n",
    "        topHeadingsConsidered=5\n",
    "        bottomHeadingsConsidered=15\n",
    "    else:\n",
    "        topHeadingsConsidered=5\n",
    "        bottomHeadingsConsidered=10\n",
    "                \n",
    "    path_json = os.path.join(os.path.abspath(os.path.join('..')), 'data', 'partitionedJSONs',f'{languageCode}')\n",
    "    print(path_json)\n",
    "    _,_,fileNames = next(os.walk(path_json))\n",
    "    print(fileNames)\n",
    "    filteredNames = [ fileName for fileName in fileNames if docFilter in fileName]\n",
    "    filteredNames = filteredNames[start:end]\n",
    "    print(filteredNames)\n",
    "    fileNameLog = os.path.join(os.path.abspath(os.path.join('..')), 'code','utils','matchLog.txt')\n",
    "    for fileNameDoc in filteredNames:\n",
    "        \n",
    "        \n",
    "        print(f\"Starting Heading Extraction For File :- {fileNameDoc}\")\n",
    "        logger = MatchLogger(f\"match logger {fileNameDoc}\", fileNameDoc, procedureType, languageCode, documentNumber, fileNameLog )\n",
    "        logger.logFlowCheckpoint(\"Starting Heading Extraction\")\n",
    "        \n",
    "        matchDocObj = MatchDocument(\n",
    "                 logger,\n",
    "                 procedureType,\n",
    "                 languageCode,\n",
    "                 documentNumber,\n",
    "                 fileNameDoc,\n",
    "                 fileNameQrd,\n",
    "                 fileNameMatchRuleBook,\n",
    "                 fileNameDocumentTypeNames,\n",
    "                 topHeadingsConsidered,\n",
    "                 bottomHeadingsConsidered,\n",
    "                 stopWordFilterLen,\n",
    "                 stopWordlanguage,\n",
    "                 isPackageLeaflet,\n",
    "                 medName)\n",
    "        df, coll = matchDocObj.matchHtmlHeaddingsWithQrd()\n",
    "        \n",
    "        print(f\"Completed Heading Extraction For File\")\n",
    "        logger.logFlowCheckpoint(\"Completed Heading Extraction For File\")\n",
    "\n",
    "        print(f\"Starting Document Annotation For File :- {fileNameDoc}\")        \n",
    "        logger.logFlowCheckpoint(\"Starting Document Annotation For File\")\n",
    "        documentAnnotationObj = DocumentAnnotation(fileNameDoc,'c20835db4b1b4e108828a8537ff41506','https://spor-sit.azure-api.net/pms/api/v2/',df,coll)\n",
    "        try:\n",
    "            pms_oms_annotation_data = documentAnnotationObj.processRegulatedAuthorizationForDoc()\n",
    "            print(pms_oms_annotation_data)\n",
    "        except:\n",
    "            pms_oms_annotation_data = None\n",
    "            print(\"Error Found\")\n",
    "            \n",
    "        print(f\"Completed Document Annotation\")        \n",
    "        logger.logFlowCheckpoint(\"Completed Document Annotation\")\n",
    "        \n",
    "        print(f\"Starting Extracting Content Between Heading For File :- {fileNameDoc}\")        \n",
    "        logger.logFlowCheckpoint(\"Starting Extracting Content Between Heading\")\n",
    "\n",
    "        #extractContentlogger = loggerCreator('ExtractContentBetween_'+ getRandomString(1))\n",
    "        extractContentlogger =  MatchLogger(f'ExtractContentBetween_{documentNumber}', fileNameDoc, procedureType, languageCode, documentNumber, fileNameLog)\n",
    "\n",
    "        extractorObj = DataBetweenHeadingsExtractor(extractContentlogger, coll, languageCode)\n",
    "        dfExtractedHierRR = extractorObj.extractContentBetweenHeadings(fileNameDoc)\n",
    "        \n",
    "        print(f\"Completed Extracting Content Between Heading\")        \n",
    "        logger.logFlowCheckpoint(\"Completed Extracting Content Between Heading\")\n",
    "        \n",
    "        #xmlLogger = loggerCreator('XmlGeneration_'+ getRandomString(1))\n",
    "        xmlLogger =  MatchLogger(f'XmlGeneration_{documentNumber}', fileNameDoc, procedureType, languageCode, documentNumber, fileNameLog)\n",
    "\n",
    "        fhirXmlGeneratorObj = FhirXmlGenerator(xmlLogger)\n",
    "        fileNameXml = fileNameDoc.replace('.json','.xml')\n",
    "        generatedXml = fhirXmlGeneratorObj.generateXml(dfExtractedHierRR,  fileNameXml)\n",
    "        \n",
    "        #fhirServiceObj = FhirService(generatedXml)\n",
    "        #fhirServiceObj.submitFhirXml()\n",
    "        print(f\"Created XML File For :- {fileNameDoc}\")        \n",
    "\n",
    "        return df,coll,dfExtractedHierRR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDocuments(domain,\n",
    "                   procedureType,\n",
    "                   languageCode,\n",
    "                   documentNumber,\n",
    "                   docFilter,\n",
    "                   fileNameQrd,\n",
    "                   fileNameMatchRuleBook,\n",
    "                   fileNameDocumentTypeNames,\n",
    "                   stopWordFilterLen=6,\n",
    "                   start=0,\n",
    "                   end=10,\n",
    "                   isPackageLeaflet=False,\n",
    "                   medName=None,\n",
    "                   fsMountName = '/mounted',\n",
    "                   localEnv= True):\n",
    "    \n",
    "    '''\n",
    "    This function was created to run the match function on multiple documents in automated fashion.\n",
    "    \n",
    "    '''\n",
    "    fileNameLog = os.path.join(os.path.abspath(os.path.join('..')),'data','FinalLog.txt')\n",
    "\n",
    "    \n",
    "\n",
    "    if documentNumber == 0:\n",
    "        topHeadingsConsidered=4\n",
    "        bottomHeadingsConsidered=6\n",
    "    elif documentNumber == 1:\n",
    "        topHeadingsConsidered=3\n",
    "        bottomHeadingsConsidered=5\n",
    "    elif documentNumber == 2:\n",
    "        topHeadingsConsidered=5\n",
    "        bottomHeadingsConsidered=15\n",
    "    else:\n",
    "        topHeadingsConsidered=5\n",
    "        bottomHeadingsConsidered=10\n",
    "                \n",
    "    path_json = os.path.join(os.path.abspath(os.path.join('..')), 'data', 'partitionedJSONs',f'{languageCode}')\n",
    "    print(path_json)\n",
    "    _,_,fileNames = next(os.walk(path_json))\n",
    "    print(fileNames)\n",
    "    filteredNames = [ fileName for fileName in fileNames if docFilter in fileName]\n",
    "    filteredNames = filteredNames[start:end]\n",
    "    print(filteredNames)\n",
    "    fileNameLog = os.path.join(os.path.abspath(os.path.join('..')), 'code','utils','matchLog.txt')\n",
    "    for fileNameDoc in filteredNames:\n",
    "        \n",
    "        flowLogger =  MatchLogger(f\"Flow Logger HTML_{getRandomString(1)}\", fileNameDoc, domain, procedureType, languageCode, \"HTML\", fileNameLog)\n",
    "        if index == 3:\n",
    "            stopWordFilterLen = 100\n",
    "            isPackageLeaflet = True\n",
    "        else:\n",
    "            stopWordFilterLen = 6\n",
    "            isPackageLeaflet = False\n",
    "            \n",
    "        df, coll = extractAndValidateHeadings(domain,\n",
    "                                    procedureType,\n",
    "                                    languageCode,\n",
    "                                    index,\n",
    "                                    fileNamePartitioned,\n",
    "                                    fileNameQrd,\n",
    "                                    fileNameMatchRuleBook,\n",
    "                                    fileNameDocumentTypeNames,\n",
    "                                    fileNameLog,\n",
    "                                    stopWordFilterLen=stopWordFilterLen,\n",
    "                                    isPackageLeaflet=isPackageLeaflet,\n",
    "                                    medName=medName,\n",
    "                                    fsMountName=fsMountName,\n",
    "                                    localEnv=localEnv)\n",
    "        \n",
    "        \n",
    "        print(f\"Completed Heading Extraction For File\")\n",
    "        flowLogger.logFlowCheckpoint(\"Completed Heading Extraction For File\")\n",
    "        \n",
    "        print(f\"Starting Document Annotation For File :- {fileNamePartitioned}\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Starting Document Annotation For File\")\n",
    "        documentAnnotationObj = DocumentAnnotation(fileNamePartitioned,'c20835db4b1b4e108828a8537ff41506','https://spor-sit.azure-api.net/pms/api/v2/',df,coll)\n",
    "        try:\n",
    "            pms_oms_annotation_data = documentAnnotationObj.processRegulatedAuthorizationForDoc()\n",
    "            print(pms_oms_annotation_data)\n",
    "        except:\n",
    "            pms_oms_annotation_data = None\n",
    "            print(\"Error Found\")\n",
    "            \n",
    "        print(f\"Completed Document Annotation\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Completed Document Annotation\")\n",
    "        \n",
    "        print(f\"Starting Extracting Content Between Heading For File :- {fileNamePartitioned}\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Starting Extracting Content Between Heading\")\n",
    "        \n",
    "        extractContentlogger =  MatchLogger(f'ExtractContentBetween_{index}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "        extractorObj = DataBetweenHeadingsExtractor(extractContentlogger, coll, domain, procedureType, languageCode, fsMountName, localEnv)\n",
    "        dfExtractedHierRR = extractorObj.extractContentBetweenHeadings(fileNamePartitioned)\n",
    "        \n",
    "        print(f\"Completed Extracting Content Between Heading\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Completed Extracting Content Between Heading\")\n",
    "        \n",
    "        xmlLogger =  MatchLogger(f'XmlGeneration_{index}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "        fhirXmlGeneratorObj = FhirXmlGenerator(xmlLogger, pms_oms_annotation_data, stylesFilePath, medName, fsMountName, localEnv)\n",
    "        fileNameXml = fileNamePartitioned.replace('.json','.xml')\n",
    "        generatedXml = fhirXmlGeneratorObj.generateXml(dfExtractedHierRR, fileNameXml)\n",
    "        \n",
    "        fhirServiceLogger =  MatchLogger(f'XML Submission Logger_{index}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "\n",
    "        fhirServiceObj = FhirService(fhirServiceLogger, generatedXml, fsMountName, localEnv)\n",
    "        fhirServiceObj.submitFhirXml()\n",
    "        print(f\"Created XML File For :- {fileNamePartitioned}\")           \n",
    "\n",
    "        #return df,coll,dfExtractedHierRR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNameQrd = 'qrd_canonical_model.csv'\n",
    "fileNameMatchRuleBook = 'ruleDict.json'\n",
    "fileNameDocumentTypeNames = 'documentTypeNames.json'\n",
    "\n",
    "fsMountName = '/mounted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToInt(x):\n",
    "    try:\n",
    "        return str(int(x))\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "def convertCollectionToDataFrame(collection):\n",
    "\n",
    "    dfExtractedHier = pd.DataFrame(collection)\n",
    "    dfExtractedHier['parent_id'] = dfExtractedHier['parent_id'].apply(\n",
    "        lambda x: convertToInt(x))\n",
    "    dfExtractedHier['id'] = dfExtractedHier['id'].apply(\n",
    "        lambda x: convertToInt(x))\n",
    "\n",
    "    return dfExtractedHier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#Comman Parameters\n",
    "procedureType = 'CAP'\n",
    "fileNameQrd = 'qrd_canonical_mode_CAP_NAP.csv'\n",
    "fileNameMatchRuleBook = 'ruleDict.json'\n",
    "fileNameDocumentTypeNames = 'documentTypeNames.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languageCode = 'es'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalydeco\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SmPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 0\n",
    "docFilter = \"SmPC.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'spanish'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertCollectionToDataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from QrdExtractor.qrdExtractor import QrdCanonical\n",
    "\n",
    "q = QrdCanonical(fileNameQrd, procedureType, languageCode, 'SmPC').ProcessQrdDataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = q.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"�\".encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dfQrd[dfQrd['id'] == r['parent_id']]['heading_id'])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAnnotationObj = DocumentAnnotation('emea-combined-h-2494-es_SmPC.json','c20835db4b1b4e108828a8537ff41506','https://spor-sit.azure-api.net/pms/api/v2/',a,b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAnnotationObj.processRegulatedAuthorizationForDoc(['',''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annex II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 1\n",
    "docFilter = \"ANEXO II.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'spanish'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 2\n",
    "docFilter = \"ANEXO III.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'spanish'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documentNumber = 3\n",
    "docFilter = \"PROSPECTO.json\"\n",
    "stopWordFilterLen = 100\n",
    "stopWordlanguage = 'spanish'\n",
    "start=0\n",
    "end=1\n",
    "isPackageLeaflet=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end,\n",
    "               isPackageLeaflet,\n",
    "               'Kalydeco'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languageCode = 'de'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalydeco\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SmPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['APPLICATIONINSIGHTS_CONNECTION_STRING'] = 'InstrumentationKey=769acdf5-503c-43e6-9736-77925ec553f0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 0\n",
    "docFilter = \"SmPC.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'german'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from match.rulebook.matchRulebook import MatchRuleBook\n",
    "\n",
    "rules= MatchRuleBook(\n",
    "            fileNameRuleBook= fileNameMatchRuleBook,\n",
    "            procedureType= procedureType,\n",
    "            languageCode= languageCode,\n",
    "            documentNumber= 0).ruleDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annex II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 1\n",
    "docFilter = \"ANHANG II.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'german'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 2\n",
    "docFilter = \"ANHANG III.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'german'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 3\n",
    "docFilter = \"PACKUNGSBEILAGE.json\"\n",
    "stopWordFilterLen = 100\n",
    "stopWordlanguage = 'german'\n",
    "start=0\n",
    "end=1\n",
    "isPackageLeaflet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end,\n",
    "               isPackageLeaflet,\n",
    "               \"Kalydeco\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulgarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "languageCode = 'bg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalydeco\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SmPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['APPLICATIONINSIGHTS_CONNECTION_STRING'] = 'InstrumentationKey=769acdf5-503c-43e6-9736-77925ec553f0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 0\n",
    "docFilter = \"SmPC.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fileNameHtml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-42b98f1e69d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                \u001b[0mstopWordFilterLen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m               )\n",
      "\u001b[1;32m<ipython-input-13-5a0c069ea44f>\u001b[0m in \u001b[0;36mparseDocuments\u001b[1;34m(domain, procedureType, languageCode, documentNumber, docFilter, fileNameQrd, fileNameMatchRuleBook, fileNameDocumentTypeNames, stopWordFilterLen, start, end, isPackageLeaflet, medName, fsMountName, localEnv)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mfileNameLog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FinalLog.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mflowLogger\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mMatchLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Flow Logger HTML_{getRandomString(1)}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileNameHtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocedureType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguageCode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HTML\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileNameLog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdocumentNumber\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fileNameHtml' is not defined"
     ]
    }
   ],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertCollectionToDataFrame(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annex II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 1\n",
    "docFilter = \"ПРИЛОЖЕНИЕ II.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertCollectionToDataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\u043f\\u043e \\u0438\\u0441\\u043a\\u0430\\u043d\\u0435      \\u043d\\u0430      \\u0415\\u0432\\u0440\\u043e\\u043f\\u0435\\u0439\\u0441\\u043a\\u0430\\u0442\\u0430      \\u0430\\u0433\\u0435\\u043d\\u0446\\u0438\\u044f \\u043f\\u043e      \\u043b\\u0435\\u043a\\u0430\\u0440\\u0441\\u0442\\u0432\\u0430\\u0442\\u0430;'.encode().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\u041f\\u043e\\u0434\\u0440\\u043e\\u0431\\u043d\\u0430 \\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u044f \\u0437\\u0430 \\u0442\\u043e\\u0432\\u0430 \\u043b\\u0435\\u043a\\u0430\\u0440\\u0441\\u0442\\u0432o \\u0435 \\u043f\\u0440\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0432\\u0435\\u043d\\u0430 \\u043d\\u0430 \\u0443\\u0435\\u0431\\u0441\\u0430\\u0439\\u0442\\u0430 \\u043d\\u0430 \\u0415\\u0432\\u0440\\u043e\\u043f\\u0435\\u0439\\u0441\\u043a\\u0430\\u0442\\u0430 \\u0430\\u0433\\u0435\\u043d\\u0446\\u0438\\u044f \\u043f\\u043e \\u043b\\u0435\\u043a\\u0430\\u0440\\u0441\\u0442\\u0432\\u0430\\u0442\\u0430 http:\\/\\/www.ema.europa.eu. \\u041f\\u043e\\u0441\\u043e\\u0447\\u0435\\u043d\\u0438 \\u0441\\u0430 \\u0441\\u044a\\u0449\\u043e \\u043b\\u0438\\u043d\\u043a\\u043e\\u0432\\u0435 \\u043a\\u044a\\u043c \\u0434\\u0440\\u0443\\u0433\\u0438 \\u0443\\u0435\\u0431\\u0441\\u0430\\u0439\\u0442\\u043e\\u0432\\u0435, \\u043a\\u044a\\u0434\\u0435\\u0442\\u043e \\u043c\\u043e\\u0436\\u0435 \\u0434\\u0430 \\u0441\\u0435 \\u043d\\u0430\\u043c\\u0435\\u0440\\u0438 \\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u044f \\u0437\\u0430 \\u0440\\u0435\\u0434\\u043a\\u0438 \\u0437\\u0430\\u0431\\u043e\\u043b\\u044f\\u0432\\u0430\\u043d\\u0438\\u044f \\u0438 \\u043b\\u0435\\u0447\\u0435\\u043d\\u0438\\u044f.\".encode().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 2\n",
    "docFilter = \"ПРИЛОЖЕНИЕ III.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a['Text'].str.find('НАЧИН НА ПРИЛОЖЕНИЕ И ПЪТ(ИЩА) НА ВЪВЕЖДАНЕ')!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertCollectionToDataFrame(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 3\n",
    "docFilter = \"ЛИСТОВКА.json\"\n",
    "stopWordFilterLen = 100\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1\n",
    "isPackageLeaflet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end,\n",
    "               isPackageLeaflet,\n",
    "               \"Kalydeco\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertCollectionToDataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" X \" in \"Какво представлява Х и за какво се използва\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.path.join('F:\\Projects\\EMA\\Repository\\EMA EPI PoC\\\\function_code\\code\\languageInfo\\documentTypeNames\\documentTypeNames.json')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame([[1,2],[3,4]],['name','age']).T\n",
    "u = t[[u'name',u'age']]\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = t[['name','age']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(u[['name']].loc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(p[['name']].loc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(a,encoding='utf-8') as f:\n",
    "    \n",
    "    documentNamesDict = json.load(f)\n",
    "    \n",
    "documentNamesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.getfilesystemencoding())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Έκδοχο με γνωστή δράση:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes(\"Έκδοχο με γνωστή δράση:\",encoding = 'utf-8').decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languageCode = 'el'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalydeco\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SmPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 0\n",
    "docFilter = \"SmPC.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'greek'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from match.rulebook.matchRulebook import MatchRuleBook\n",
    "\n",
    "r = MatchRuleBook(fileNameMatchRuleBook, procedureType, languageCode, documentNumber)\n",
    "\n",
    "from match.matchStrings.matchStrings import MatchStrings\n",
    "m = MatchStrings(logger, documentNumber, r, 6, \"greek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.matchStrings('Κύηση', 'Κύηση',23, avoidLowerCaseMatch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Έκδοχο(α) με γνωστή δράση'.encode().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annex II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 1\n",
    "docFilter = \"ΠΑΡΑΡΤΗΜΑ ΙΙ.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'greek'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 2\n",
    "docFilter = \"ΠΑΡΑΡΤΗΜΑ ΙΙΙ.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 3\n",
    "docFilter = \"ΧΡΗΣΗΣ.json\"\n",
    "stopWordFilterLen = 100\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1\n",
    "isPackageLeaflet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end,\n",
    "               isPackageLeaflet,\n",
    "               \"Kalydeco\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertCollectionToDataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languageCode = 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalydeco\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SmPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 0\n",
    "docFilter = \"SmPC.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'english'\n",
    "start=10\n",
    "end="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annex II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 1\n",
    "docFilter = \"ANNEX II.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 2\n",
    "docFilter = \"ANNEX III.json\"\n",
    "stopWordFilterLen = 6\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentNumber = 3\n",
    "docFilter = \"LEAFLET.json\"\n",
    "stopWordFilterLen = 100\n",
    "stopWordlanguage = 'english'\n",
    "start=0\n",
    "end=1\n",
    "isPackageLeaflet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b,c = parseDocuments(procedureType,\n",
    "               languageCode,\n",
    "               documentNumber,\n",
    "               docFilter,\n",
    "               fileNameQrd,\n",
    "               fileNameMatchRuleBook,\n",
    "               fileNameDocumentTypeNames,\n",
    "               stopWordFilterLen,\n",
    "               start,\n",
    "               end,\n",
    "               isPackageLeaflet,\n",
    "               \"Kalydeco\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertCollectionToDataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = MatchLogger(\"MatchLogger\",'Kalydeco II-86-PI-clean_ PACKAGE LEAFLET.json', 'CAP', 'en', 'SmPC', fileNameLog = os.path.join(os.path.abspath(os.path.join('..')), 'code','utils','matchLog.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from match.rulebook.matchRulebook import MatchRuleBook\n",
    "\n",
    "rules= MatchRuleBook(\n",
    "            fileNameRuleBook= fileNameMatchRuleBook,\n",
    "            procedureType= procedureType,\n",
    "            languageCode= languageCode,\n",
    "            documentNumber= 2).ruleDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from match.matchStrings.matchStrings import MatchStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchString = MatchStrings(logger, 2, rules, 6, 'german')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o,t = 'ANGABEN AUF DER ZWISCHENVERPACKUNG','ANGABEN <AUF DER ÄUSSEREN UMHÜLLUNG> <UND> <AUF DEM BEHÄLTNIS> <UND> <AUF DER ZWISCHENVERPACKUNG>'\n",
    "\n",
    "#o = o.encode()\n",
    "#print(o.decode())\n",
    "matchString.matchStrings(o,t,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNameDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
