{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNameQrd = 'qrd_canonical_model.csv'\n",
    "fileNameMatchRuleBook = 'ruleDict.json'\n",
    "fileNameDocumentTypeNames = 'documentTypeNames.json'\n",
    "\n",
    "fsMountName = '/mounted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "from bs4 import NavigableString, BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import string\n",
    "\n",
    "from utils.config import config\n",
    "from utils.logger.logger import loggerCreator\n",
    "\n",
    "# ePI Modules\n",
    "from parse.rulebook.rulebook import StyleRulesDictionary\n",
    "\n",
    "from parse.extractor.parser import parserExtractor\n",
    "from match.matchDocument.matchDocument import MatchDocument\n",
    "from documentAnnotation.documentAnnotation import DocumentAnnotation\n",
    "from htmlDocTypePartitioner.partition import DocTypePartitioner\n",
    "from extractContentBetweenHeadings.dataBetweenHeadingsExtractor import DataBetweenHeadingsExtractor\n",
    "from fhirXmlGenerator.fhirXmlGenerator import FhirXmlGenerator\n",
    "from fhirService.fhirService import FhirService\n",
    "from utils.logger.matchLogger import MatchLogger\n",
    "from languageInfo.documentTypeNames.documentTypeNames import DocumentTypeNames\n",
    "\n",
    "\n",
    "class FolderNotFoundError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def getRandomString(N):\n",
    "    str_ = ''.join(random.choice(string.ascii_uppercase + string.digits\n",
    "                                 + string.ascii_lowercase) for _ in range(N))\n",
    "    return str_\n",
    "\n",
    "\n",
    "def convertHtmlToJson(domain, procedureType, languageCode, fileNameHtml, fileNameQrd, fileNameLog, fsMountName, localEnv):\n",
    "\n",
    "    if localEnv is True:\n",
    "        pathSep = \"\\\\\"\n",
    "        module_path = os.path.join(os.path.abspath(os.path.join('..')), 'data', 'converted_to_html', f'{domain}', f'{procedureType}', f'{languageCode}')\n",
    "    else:\n",
    "        pathSep = \"/\"\n",
    "        module_path = os.path.join(f'{fsMountName}', 'data', 'converted_to_html', f'{domain}', f'{procedureType}', f'{languageCode}')\n",
    "    \n",
    "    # Generate output folder path\n",
    "    output_json_path = module_path.replace('converted_to_html', 'outputJSON')\n",
    "\n",
    "    \"\"\"\n",
    "        Check if input folder exists, else throw exception\n",
    "    \"\"\"\n",
    "    if(os.path.exists(module_path)):\n",
    "        filenames = glob.glob(os.path.join(module_path, fileNameHtml))\n",
    "\n",
    "        # Create language specific folder in outputJSON folder if it doesn't exist\n",
    "        if(not os.path.exists(output_json_path)):\n",
    "            os.mkdir(output_json_path)\n",
    "        logger = MatchLogger(f'Parser_{getRandomString(1)}', fileNameHtml,\n",
    "                             domain, procedureType, languageCode, \"HTML\", fileNameLog)\n",
    "\n",
    "        styleLogger = MatchLogger(\n",
    "            f'Style Dictionary_{getRandomString(1)}', fileNameHtml, domain, procedureType, languageCode, \"HTML\", fileNameLog)\n",
    "\n",
    "        styleRulesObj = StyleRulesDictionary(styleLogger,\n",
    "                                             language=languageCode,\n",
    "                                             fileName=fileNameQrd,\n",
    "                                             domain=domain,\n",
    "                                             procedureType=procedureType,\n",
    "                                             fsMountName=fsMountName,\n",
    "                                             localEnv=localEnv)\n",
    "\n",
    "        parserObj = parserExtractor(config, logger, styleRulesObj.styleRuleDict,\n",
    "                                    styleRulesObj.styleFeatureKeyList,\n",
    "                                    styleRulesObj.qrd_section_headings)\n",
    "\n",
    "        for input_filename in filenames:\n",
    "          # if(input_filename.find('Kalydeco II-86-PI-clean')!=-1):\n",
    "            output_filename = input_filename.replace('converted_to_html', 'outputJSON')\n",
    "            style_filepath =  output_filename.replace('.html','.txt')\n",
    "            style_filepath =  style_filepath.replace('.txtl','.txt')\n",
    "            style_filepath =  style_filepath.replace('.htm','.txt')\n",
    "            print(\"-------------\",style_filepath,\"-----------------\")\n",
    "\n",
    "            try:\n",
    "                print(\"Here\")\n",
    "                os.makedirs(style_filepath)\n",
    "            except Exception:\n",
    "                print(\"Already Exists\")\n",
    "\n",
    "\n",
    "            output_filename = output_filename.replace('.html', '.json')\n",
    "            output_filename = output_filename.replace('.htm', '.json')\n",
    "            print(input_filename, output_filename)\n",
    "            parserObj.createPIJsonFromHTML(input_filepath=input_filename,\n",
    "                                           output_filepath=output_filename,\n",
    "                                           style_filepath = style_filepath,\n",
    "                                           img_base64_dict=parserObj.convertImgToBase64(input_filename)\n",
    "                                           )\n",
    "            \n",
    "        return output_filename.split(pathSep)[-1], style_filepath\n",
    "    else:\n",
    "        try:    \n",
    "            raise FolderNotFoundError(module_path + \" not found\")\n",
    "        except:  \n",
    "            logger.logFlowCheckpoint(\"Folder For Language Code Not Found In Input File\")\n",
    "            logger.logException(\"Folder For Language Code Not Found In Input File\")\n",
    "        raise FolderNotFoundError(module_path + \" not found\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def splitJson(domain, procedureType, languageCode, fileNameJson, fileNameQrd, fileNameLog, fsMountName, localEnv):\n",
    "\n",
    "    styleLogger = MatchLogger(\n",
    "        f'Style Dictionary_{getRandomString(1)}', fileNameJson, domain, procedureType, languageCode, \"Json\", fileNameLog)\n",
    "\n",
    "    styleRulesObj = StyleRulesDictionary(styleLogger,\n",
    "                                             language=languageCode,\n",
    "                                             fileName=fileNameQrd,\n",
    "                                             domain=domain,\n",
    "                                             procedureType=procedureType,\n",
    "                                             fsMountName=fsMountName,\n",
    "                                             localEnv=localEnv)\n",
    "    if localEnv is True:\n",
    "        path_json = os.path.join(os.path.abspath(os.path.join(\n",
    "                '..')), 'data', 'outputJSON', domain, procedureType, languageCode, fileNameJson)\n",
    "    else:\n",
    "        path_json = os.path.join(f'{fsMountName}', 'data', 'outputJSON', domain,  procedureType, languageCode, fileNameJson)\n",
    "        \n",
    "    partitionLogger = MatchLogger(\n",
    "        f'Partition_{getRandomString(1)}', fileNameJson, domain, procedureType, languageCode, \"Json\", fileNameLog)\n",
    "\n",
    "    partitioner = DocTypePartitioner(partitionLogger, localEnv)\n",
    "\n",
    "    partitionedJsonPaths = partitioner.partitionHtmls(\n",
    "        styleRulesObj.qrd_section_headings, path_json)\n",
    "\n",
    "    return partitionedJsonPaths\n",
    "\n",
    "\n",
    "def extractAndValidateHeadings(domain,\n",
    "                               procedureType,\n",
    "                               languageCode,\n",
    "                               documentNumber,\n",
    "                               fileNameDoc,\n",
    "                               fileNameQrd,\n",
    "                               fileNameMatchRuleBook,\n",
    "                               fileNameDocumentTypeNames,\n",
    "                               fileNameLog,\n",
    "                               stopWordFilterLen=6,\n",
    "                               isPackageLeaflet=False,\n",
    "                               medName=None,\n",
    "                               fsMountName='/mounted',\n",
    "                               localEnv=False):\n",
    "\n",
    "    if documentNumber == 0:\n",
    "        topHeadingsConsidered = 4\n",
    "        bottomHeadingsConsidered = 6\n",
    "    elif documentNumber == 1:\n",
    "        topHeadingsConsidered = 3\n",
    "        bottomHeadingsConsidered = 5\n",
    "    elif documentNumber == 2:\n",
    "        topHeadingsConsidered = 5\n",
    "        bottomHeadingsConsidered = 15\n",
    "    else:\n",
    "        topHeadingsConsidered = 5\n",
    "        bottomHeadingsConsidered = 10\n",
    "\n",
    "    print(f\"Starting Heading Extraction For File :- {fileNameDoc}\")\n",
    "    logger = MatchLogger(f\"Heading Extraction {fileNameDoc}\", fileNameDoc, domain, procedureType, languageCode, documentNumber, fileNameLog)\n",
    "    logger.logFlowCheckpoint(\"Starting Heading Extraction\")\n",
    "\n",
    "    stopWordlanguage = DocumentTypeNames(\n",
    "        fileNameDocumentTypeNames=fileNameDocumentTypeNames,\n",
    "        languageCode=languageCode,\n",
    "        domain=domain,\n",
    "        procedureType=procedureType,\n",
    "        documentNumber=documentNumber,\n",
    "        fsMountName=fsMountName,\n",
    "        localEnv=localEnv).extractStopWordLanguage()\n",
    "\n",
    "    matchDocObj = MatchDocument(\n",
    "        logger,\n",
    "        domain,\n",
    "        procedureType,\n",
    "        languageCode,\n",
    "        documentNumber,\n",
    "        fileNameDoc,\n",
    "        fileNameQrd,\n",
    "        fileNameMatchRuleBook,\n",
    "        fileNameDocumentTypeNames,\n",
    "        topHeadingsConsidered,\n",
    "        bottomHeadingsConsidered,\n",
    "        stopWordFilterLen,\n",
    "        stopWordlanguage,\n",
    "        isPackageLeaflet,\n",
    "        medName,\n",
    "        fsMountName,\n",
    "        localEnv)\n",
    "    df, coll = matchDocObj.matchHtmlHeaddingsWithQrd()\n",
    "\n",
    "    return df, coll\n",
    "\n",
    "\n",
    "def parseDocument(htmlDocPath, fileNameQrd, fileNameMatchRuleBook, fileNameDocumentTypeNames, fsMountName = '/mounted', localEnv= False, medName = None):\n",
    "    \n",
    "    if localEnv is True:\n",
    "        pathSep = \"\\\\\"\n",
    "        fileNameLog = os.path.join(os.path.abspath(os.path.join('..')),'data','FinalLog.txt')\n",
    "    else:\n",
    "        pathSep = \"/\"\n",
    "        fileNameLog = os.path.join(f'{fsMountName}','data','FinalLog.txt')\n",
    "    pathComponents = htmlDocPath.split(pathSep)\n",
    "    print(pathComponents)\n",
    "    fileNameHtml = pathComponents[-1]\n",
    "    languageCode =  pathComponents[-2]\n",
    "    procedureType = pathComponents[-3]\n",
    "    domain = pathComponents[-4]\n",
    "\n",
    "    #procedureType = \"CAP\"\n",
    "    print(fileNameHtml,languageCode,procedureType)\n",
    "    \n",
    "    \n",
    "    \n",
    "    flowLogger =  MatchLogger(f\"Flow Logger HTML_{getRandomString(1)}\", fileNameHtml, domain, procedureType, languageCode, \"HTML\", fileNameLog)\n",
    "\n",
    "    flowLogger.logFlowCheckpoint(\"Starting HTML Conversion To Json\")\n",
    "    ###Convert Html to Json\n",
    "    fileNameJson, stylesFilePath = convertHtmlToJson( domain, procedureType, languageCode, fileNameHtml, fileNameQrd, fileNameLog, fsMountName, localEnv)\n",
    "    \n",
    "    flowLogger.logFlowCheckpoint(\"Completed HTML Conversion To Json\")\n",
    "\n",
    "    flowLogger.logFlowCheckpoint(\"Starting Json Split\")\n",
    "\n",
    "    ###Split Uber Json to multiple Jsons for each category.\n",
    "    partitionedJsonPaths = splitJson(domain, procedureType, languageCode, fileNameJson, fileNameQrd, fileNameLog, fsMountName, localEnv)\n",
    "    \n",
    "    partitionedJsonPaths = [ path.split(pathSep)[-1] for path in partitionedJsonPaths]\n",
    "    flowLogger.logFlowCheckpoint(str(partitionedJsonPaths))\n",
    "    \n",
    "    flowLogger.logFlowCheckpoint(\"Completed Json Split\")\n",
    "    \n",
    "    flowLogger.logFlowCheckpoint(\"Started Processing Partitioned Jsons\")\n",
    "    \n",
    "    for index, fileNamePartitioned in enumerate(partitionedJsonPaths):\n",
    "        \n",
    "        flowLogger.logFlowCheckpoint(f\"\\n\\n\\n\\n||||||||||||||||||||||||||||||||{str(index)} ||||| {str(fileNamePartitioned)}||||||||||||||||||||||||||||||||\\n\\n\\n\\n\")\n",
    "        \n",
    "        if index == 3:\n",
    "            stopWordFilterLen = 100\n",
    "            isPackageLeaflet = True\n",
    "        else:\n",
    "            stopWordFilterLen = 6\n",
    "            isPackageLeaflet = False\n",
    "            \n",
    "        df, coll = extractAndValidateHeadings(domain,\n",
    "                                    procedureType,\n",
    "                                    languageCode,\n",
    "                                    index,\n",
    "                                    fileNamePartitioned,\n",
    "                                    fileNameQrd,\n",
    "                                    fileNameMatchRuleBook,\n",
    "                                    fileNameDocumentTypeNames,\n",
    "                                    fileNameLog,\n",
    "                                    stopWordFilterLen=stopWordFilterLen,\n",
    "                                    isPackageLeaflet=isPackageLeaflet,\n",
    "                                    medName=medName,\n",
    "                                    fsMountName=fsMountName,\n",
    "                                    localEnv=localEnv)\n",
    "        \n",
    "        \n",
    "        print(f\"Completed Heading Extraction For File\")\n",
    "        flowLogger.logFlowCheckpoint(\"Completed Heading Extraction For File\")\n",
    "        \n",
    "        print(f\"Starting Document Annotation For File :- {fileNamePartitioned}\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Starting Document Annotation For File\")\n",
    "        documentAnnotationObj = DocumentAnnotation(fileNamePartitioned,'c20835db4b1b4e108828a8537ff41506','https://spor-sit.azure-api.net/pms/api/v2/',df,coll)\n",
    "        try:\n",
    "            pms_oms_annotation_data = documentAnnotationObj.processRegulatedAuthorizationForDoc()\n",
    "            print(pms_oms_annotation_data)\n",
    "        except:\n",
    "            pms_oms_annotation_data = None\n",
    "            print(\"Error Found\")\n",
    "            \n",
    "        print(f\"Completed Document Annotation\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Completed Document Annotation\")\n",
    "        \n",
    "        print(f\"Starting Extracting Content Between Heading For File :- {fileNamePartitioned}\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Starting Extracting Content Between Heading\")\n",
    "        \n",
    "        extractContentlogger =  MatchLogger(f'ExtractContentBetween_{index}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "        extractorObj = DataBetweenHeadingsExtractor(extractContentlogger, coll, domain, procedureType, languageCode, fsMountName, localEnv)\n",
    "        dfExtractedHierRR = extractorObj.extractContentBetweenHeadings(fileNamePartitioned)\n",
    "        \n",
    "        print(f\"Completed Extracting Content Between Heading\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Completed Extracting Content Between Heading\")\n",
    "        \n",
    "        xmlLogger =  MatchLogger(f'XmlGeneration_{index}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "        fhirXmlGeneratorObj = FhirXmlGenerator(xmlLogger, pms_oms_annotation_data, stylesFilePath, medName, fsMountName, localEnv)\n",
    "        fileNameXml = fileNamePartitioned.replace('.json','.xml')\n",
    "        generatedXml = fhirXmlGeneratorObj.generateXml(dfExtractedHierRR, fileNameXml)\n",
    "        \n",
    "        fhirServiceLogger =  MatchLogger(f'XML Submission Logger_{index}', fileNamePartitioned, procedureType, languageCode, index, fileNameLog)\n",
    "\n",
    "        fhirServiceObj = FhirService(fhirServiceLogger, generatedXml, fsMountName, localEnv)\n",
    "        fhirServiceObj.submitFhirXml()\n",
    "        print(f\"Created XML File For :- {fileNamePartitioned}\")        \n",
    "\n",
    "        #return df,coll,dfExtractedHierRR\n",
    "    \n",
    "    flowLogger.logFlowCheckpoint(\"Completed Processing Partitioned Jsons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-07 18:40:01,576 : Flow Logger HTML_2 : Starting HTML Conversion To Json | H | CAP |  en | HTML | Adakveo-4874 EN PI.html\n",
      "2021-05-07 18:40:01,587 : Style Dictionary_o : Reading style dictionary in file: rule_dictionary_en.json | H | CAP |  en | HTML | Adakveo-4874 EN PI.html\n",
      "2021-05-07 18:40:01,633 : Style Dictionary_o : Qrd Section Keys Retrieved For Style Dictionary: ANNEX I, ANNEX II, ANNEX III, B. PACKAGE LEAFLET | H | CAP |  en | HTML | Adakveo-4874 EN PI.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F:', 'Projects', 'EMA', 'Repository', 'EMA EPI PoC', 'function_code', 'data', 'converted_to_html', 'H', 'CAP', 'en', 'Adakveo-4874 EN PI.html']\n",
      "Adakveo-4874 EN PI.html en CAP\n",
      "------------- F:\\Projects\\EMA\\Repository\\EMA EPI PoC\\function_code\\data\\outputJSON\\H\\CAP\\en\\Adakveo-4874 EN PI.txt -----------------\n",
      "Here\n",
      "Already Exists\n",
      "F:\\Projects\\EMA\\Repository\\EMA EPI PoC\\function_code\\data\\converted_to_html\\H\\CAP\\en\\Adakveo-4874 EN PI.html F:\\Projects\\EMA\\Repository\\EMA EPI PoC\\function_code\\data\\outputJSON\\H\\CAP\\en\\Adakveo-4874 EN PI.json\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'F:\\\\Projects\\\\EMA\\\\Repository\\\\EMA EPI PoC\\\\function_code\\\\data\\\\outputJSON\\\\H\\\\CAP\\\\en\\\\Adakveo-4874 EN PI.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3f6290647f0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparseDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F:\\\\Projects\\\\EMA\\\\Repository\\\\EMA EPI PoC\\\\function_code\\\\data\\\\converted_to_html\\\\H\\\\CAP\\\\en\\\\Adakveo-4874 EN PI.html\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileNameQrd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileNameMatchRuleBook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileNameDocumentTypeNames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmedName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Aerius\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfsMountName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/mounted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocalEnv\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-00dd7e3d56f2>\u001b[0m in \u001b[0;36mparseDocument\u001b[1;34m(htmlDocPath, fileNameQrd, fileNameMatchRuleBook, fileNameDocumentTypeNames, fsMountName, localEnv, medName)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[0mflowLogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogFlowCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting HTML Conversion To Json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;31m###Convert Html to Json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m     \u001b[0mfileNameJson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstylesFilePath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertHtmlToJson\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocedureType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguageCode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileNameHtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileNameQrd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileNameLog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfsMountName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocalEnv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mflowLogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogFlowCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Completed HTML Conversion To Json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-00dd7e3d56f2>\u001b[0m in \u001b[0;36mconvertHtmlToJson\u001b[1;34m(domain, procedureType, languageCode, fileNameHtml, fileNameQrd, fileNameLog, fsMountName, localEnv)\u001b[0m\n\u001b[0;32m     99\u001b[0m                                            \u001b[0moutput_filepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                                            \u001b[0mstyle_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstyle_filepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                                            \u001b[0mimg_base64_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparserObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvertImgToBase64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                                            )\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Projects\\EMA\\Repository\\EMA EPI PoC\\function_code\\code\\parse\\extractor\\parser.py\u001b[0m in \u001b[0;36mcreatePIJsonFromHTML\u001b[1;34m(self, input_filepath, output_filepath, style_filepath, img_base64_dict)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mcss_in_style\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle_filepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstyle_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m                 \u001b[0mstyle_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcss_in_style\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[0mstyle_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'F:\\\\Projects\\\\EMA\\\\Repository\\\\EMA EPI PoC\\\\function_code\\\\data\\\\outputJSON\\\\H\\\\CAP\\\\en\\\\Adakveo-4874 EN PI.txt'"
     ]
    }
   ],
   "source": [
    "parseDocument(\"F:\\\\Projects\\\\EMA\\\\Repository\\\\EMA EPI PoC\\\\function_code\\\\data\\\\converted_to_html\\\\H\\\\CAP\\\\en\\\\Adakveo-4874 EN PI.html\", fileNameQrd, fileNameMatchRuleBook, fileNameDocumentTypeNames, medName = \"Aerius\", fsMountName = '/mounted', localEnv= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
