{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the final Noteebok to be used for following :- \n",
    "\n",
    "- ### Word to HTML conversion and zip file creation for all types of documents.\n",
    "- ### Final conversion/parsing of documents (zip files) for all types of documents.\n",
    "<br>\n",
    "\n",
    "## Steps for executing this notebook\n",
    "\n",
    "1. Open terminal and change cwd to \"conversion/code\" directory.\n",
    "2. Run command <i> jupyter notebook </i>\n",
    "3. On the jupyter notebook, open the <i>dev notebook final v10.ipynb</i> notebook.\n",
    "4. Execute first code cell #1  for importing the basis module and changing the dir to the correct path.<br><i> Please note, never run this cell multiple times in a kernel session <i>\n",
    "\n",
    "### Word to HTML Conversion\n",
    "\n",
    "- Run cell #2 , this will convert all the word files present at \"conversion\\data\\ingest\" to HTML and create a zip file for each document.\n",
    "\n",
    "### Document Conversion \n",
    "\n",
    "- Run Cells #3, #4, #5 , These cell will create the required functions for the conversion process.\n",
    "\n",
    "- Function RunAll (Dev) and RunAllTest (Test) are used for executing the conversion process in the respective environments.\n",
    "\n",
    "- For example all the cell starting from cell #6 and beyond have examples on how to run these function.\n",
    "\n",
    "- This function take a list of zip file names as input parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "os.chdir(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "import psutil\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "from bs4 import NavigableString, BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "from utils.config import config\n",
    "from utils.logger.logger import loggerCreator\n",
    "\n",
    "# ePI Modules\n",
    "from parse.rulebook.rulebook import StyleRulesDictionary\n",
    "\n",
    "from parse.extractor.parser import parserExtractor\n",
    "from match.matchDocument.matchDocument import MatchDocument\n",
    "from documentAnnotation.documentAnnotation import DocumentAnnotation\n",
    "from htmlDocTypePartitioner.partition import DocTypePartitioner\n",
    "from extractContentBetweenHeadings.dataBetweenHeadingsExtractor import DataBetweenHeadingsExtractor\n",
    "from fhirXmlGenerator.fhirXmlGenerator import FhirXmlGenerator\n",
    "from fhirService.fhirService import FhirService\n",
    "from utils.logger.matchLogger import MatchLogger\n",
    "from languageInfo.documentTypeNames.documentTypeNames import DocumentTypeNames\n",
    "from listBundle.addAndUpdateListBundle.addAndUpdateListBundle import ListBundleHandler\n",
    "\n",
    "class FolderNotFoundError(Exception):\n",
    "    pass\n",
    "\n",
    "class Metrics:\n",
    "    \n",
    "    def __init__(self, logFileName, logger):\n",
    "        self.logFileName = logFileName\n",
    "        self.start()\n",
    "        self.writer = open(self.logFileName, 'a')\n",
    "        self.writer.write(\"StepName,Time,Current Memory,Peak Memory,Used Ram Percentage\\n\")\n",
    "        self.finalPeak = 0\n",
    "        self.finalTotalTime = 0\n",
    "        self.finalUsedRamPerc = 0\n",
    "        self.logger = logger\n",
    "    \n",
    "    def start(self):\n",
    "        self.startTime = time.time()\n",
    "        tracemalloc.start()\n",
    "    \n",
    "    def getMetric(self, msg):\n",
    "        \n",
    "        self.endTime = time.time()\n",
    "        \n",
    "        self.totalTime = self.endTime - self.startTime\n",
    "        \n",
    "        \n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        current = current / 10**6\n",
    "        peak = peak / 10**6\n",
    "        \n",
    "        usedRamPerc = psutil.virtual_memory()[2]\n",
    "        \n",
    "        self.finalPeak = max(self.finalPeak, peak)\n",
    "        self.finalUsedRamPerc = max(self.finalUsedRamPerc, usedRamPerc)\n",
    "\n",
    "        self.finalTotalTime = self.finalTotalTime + self.totalTime\n",
    "        #self.finalTotalTime = round(self.finalTotalTime/60,3)\n",
    "        \n",
    "        outputString = f\"{msg},{round(self.totalTime/60,4)} Min,{current} MB,{peak} MB,{usedRamPerc}%\\n\"\n",
    "        \n",
    "        self.logger.logFlowCheckpoint(f\"{outputString}\")\n",
    "        \n",
    "        print(f\"Metrics : {outputString}\")\n",
    "        self.writer.write(outputString)\n",
    "        tracemalloc.stop()\n",
    "        tracemalloc.start()\n",
    "        self.startTime = time.time()\n",
    "    def end(self):\n",
    "        \n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        current = current / 10**6\n",
    "        outputString = f\"Final Metrics,{round(self.finalTotalTime/60,4)} Min,{current} MB,{self.finalPeak} MB,{self.finalUsedRamPerc}%\\n\"\n",
    "        print(f\"Metrics : {outputString}\")\n",
    "        self.logger.logFlowCheckpoint(f\"{outputString}\")\n",
    "        self.writer.write(outputString)\n",
    "        self.writer.close()\n",
    "        tracemalloc.stop()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def convertToInt(x):\n",
    "    try:\n",
    "        return str(int(x))\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "def convertCollectionToDataFrame(collection):\n",
    "\n",
    "    dfExtractedHier = pd.DataFrame(collection)\n",
    "    dfExtractedHier['parent_id'] = dfExtractedHier['parent_id'].apply(\n",
    "        lambda x: convertToInt(x))\n",
    "    dfExtractedHier['id'] = dfExtractedHier['id'].apply(\n",
    "        lambda x: convertToInt(x))\n",
    "\n",
    "    return dfExtractedHier\n",
    "\n",
    "def getRandomString(N):\n",
    "    str_ = ''.join(random.choice(string.ascii_uppercase + string.digits\n",
    "                                 + string.ascii_lowercase) for _ in range(N))\n",
    "    return str_\n",
    "\n",
    "\n",
    "def convertHtmlToJson(controlBasePath,\n",
    "                      basePath,\n",
    "                      domain,\n",
    "                      procedureType,\n",
    "                      languageCode,\n",
    "                      htmlDocName,\n",
    "                      fileNameQrd,\n",
    "                      fileNameLog,\n",
    "                      NAPDocumentNumber):\n",
    "\n",
    "    module_path = os.path.join(basePath)\n",
    "\n",
    "    if \"/\" in basePath:\n",
    "        pathSep = \"/\"\n",
    "    else:\n",
    "        pathSep = \"\\\\\"\n",
    "    \n",
    "    # Generate output folder path\n",
    "    output_json_path = os.path.join(basePath, 'outputJSON')\n",
    "\n",
    "    \"\"\"\n",
    "        Check if input folder exists, else throw exception\n",
    "    \"\"\"\n",
    "    if(os.path.exists(module_path)):\n",
    "        filenames = glob.glob(os.path.join(module_path, htmlDocName))\n",
    "\n",
    "        # Create language specific folder in outputJSON folder if it doesn't exist\n",
    "        if(not os.path.exists(output_json_path)):\n",
    "            os.mkdir(output_json_path)\n",
    "        logger = MatchLogger(f'Parser_{getRandomString(1)}', htmlDocName,\n",
    "                             domain, procedureType, languageCode, \"HTML\", fileNameLog)\n",
    "        \n",
    "        ###################################\n",
    "        #########  STEP 2 START  ##########\n",
    "        \n",
    "        styleLogger = MatchLogger(\n",
    "            f'Style Dictionary_{getRandomString(1)}', htmlDocName, domain, procedureType, languageCode, \"HTML\", fileNameLog)\n",
    "        if procedureType == \"CAP\":\n",
    "            styleRulesObj = StyleRulesDictionary(logger=styleLogger,\n",
    "                                                 controlBasePath=controlBasePath,\n",
    "                                                 language=languageCode,\n",
    "                                                 fileName=fileNameQrd,\n",
    "                                                 domain=domain,\n",
    "                                                 procedureType=procedureType)\n",
    "        else:\n",
    "            if NAPDocumentNumber == None:\n",
    "                raise Exception(\"Missing NAPDocumentNumber\")\n",
    "            \n",
    "            styleRulesObj = StyleRulesDictionary(logger=styleLogger,\n",
    "                                                 controlBasePath=controlBasePath,\n",
    "                                                 language=languageCode,\n",
    "                                                 fileName=fileNameQrd,\n",
    "                                                 domain=domain,\n",
    "                                                 procedureType=procedureType,\n",
    "                                                 NAPDocumentNumber = NAPDocumentNumber\n",
    "                                                 )\n",
    "        \n",
    "        ###############  END   ############\n",
    "        \n",
    "        ###################################        \n",
    "        #########  STEP 3 START ###########\n",
    "        \n",
    "        parserObj = parserExtractor(config, logger, styleRulesObj.styleRuleDict,\n",
    "                                    styleRulesObj.styleFeatureKeyList,\n",
    "                                    styleRulesObj.qrd_section_headings)\n",
    "        \n",
    "        for input_filename in filenames:\n",
    "          # if(input_filename.find('Kalydeco II-86-PI-clean')!=-1):\n",
    "            output_filename = os.path.join(output_json_path, htmlDocName)\n",
    "            style_filepath =  output_filename.replace('.html','.txt')\n",
    "            style_filepath =  style_filepath.replace('.txtl','.txt')\n",
    "            style_filepath =  style_filepath.replace('.htm','.txt')\n",
    "            print(\"-------------\",style_filepath,\"-----------------\")\n",
    "\n",
    "            output_filename = output_filename.replace('.html', '.json')\n",
    "            output_filename = output_filename.replace('.htm', '.json')\n",
    "            print(input_filename, output_filename)\n",
    "            parserObj.createPIJsonFromHTML(input_filepath=input_filename,\n",
    "                                           output_filepath=output_filename,\n",
    "                                           style_filepath = style_filepath,\n",
    "                                           img_base64_dict=parserObj.convertImgToBase64(input_filename)\n",
    "                                           )\n",
    "        #return parserObj, input_filename, output_filename, style_filepath\n",
    "        return output_filename.split(pathSep)[-1], style_filepath\n",
    "    \n",
    "        ##############  END ###############\n",
    "    else:\n",
    "        try:    \n",
    "            raise FolderNotFoundError(module_path + \" not found\")\n",
    "        except:  \n",
    "            logger.logFlowCheckpoint(\"Folder For Language Code Not Found In Input File\")\n",
    "            logger.logException(\"Folder For Language Code Not Found In Input File\")\n",
    "        raise FolderNotFoundError(module_path + \" not found\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def splitJson(controlBasePath, basePath, domain, procedureType, languageCode, fileNameJson, fileNameQrd, fileNameLog):\n",
    "\n",
    "    styleLogger = MatchLogger(\n",
    "        f'Style Dictionary_{getRandomString(1)}', fileNameJson, domain, procedureType, languageCode, \"Json\", fileNameLog)\n",
    "\n",
    "    styleRulesObj = StyleRulesDictionary(logger=styleLogger,\n",
    "                                        controlBasePath=controlBasePath,\n",
    "                                        language=languageCode,\n",
    "                                        fileName=fileNameQrd,\n",
    "                                        domain=domain,\n",
    "                                        procedureType=procedureType\n",
    "                                        )\n",
    "    \n",
    "    path_json = os.path.join(basePath,'outputJSON', fileNameJson)\n",
    "    print(\"PathJson\",path_json)\n",
    "    partitionLogger = MatchLogger(\n",
    "        f'Partition_{getRandomString(1)}', fileNameJson, domain, procedureType, languageCode, \"Json\", fileNameLog)\n",
    "\n",
    "    partitioner = DocTypePartitioner(partitionLogger, domain, procedureType)\n",
    "\n",
    "    partitionedJsonPaths = partitioner.partitionHtmls(\n",
    "        styleRulesObj.qrd_section_headings, path_json)\n",
    "\n",
    "    return partitionedJsonPaths\n",
    "\n",
    "\n",
    "def extractAndValidateHeadings(controlBasePath,\n",
    "                                basePath,\n",
    "                                domain,\n",
    "                                procedureType,\n",
    "                                languageCode,\n",
    "                                documentNumber,\n",
    "                                fileNameDoc,\n",
    "                                fileNameQrd,\n",
    "                                fileNameMatchRuleBook,\n",
    "                                fileNameDocumentTypeNames,\n",
    "                                fileNameLog,\n",
    "                                stopWordFilterLen=6,\n",
    "                                isPackageLeaflet=False,\n",
    "                                medName=None\n",
    "                                ):\n",
    "\n",
    "    if documentNumber == 0:\n",
    "        topHeadingsConsidered = 4\n",
    "        bottomHeadingsConsidered = 6\n",
    "    elif documentNumber == 1:\n",
    "        topHeadingsConsidered = 3\n",
    "        bottomHeadingsConsidered = 5\n",
    "    elif documentNumber == 2:\n",
    "        topHeadingsConsidered = 5\n",
    "        bottomHeadingsConsidered = 15\n",
    "    else:\n",
    "        topHeadingsConsidered = 5\n",
    "        bottomHeadingsConsidered = 10\n",
    "\n",
    "    print(f\"Starting Heading Extraction For File :- {fileNameDoc}\")\n",
    "    logger = MatchLogger(f\"Heading Extraction {fileNameDoc}_{getRandomString(1)}\", fileNameDoc, domain, procedureType, languageCode, documentNumber, fileNameLog)\n",
    "    logger.logFlowCheckpoint(\"Starting Heading Extraction\")\n",
    "    \n",
    "    ###################################\n",
    "    #########  STEP 4 #################\n",
    "    \n",
    "    \n",
    "    stopWordlanguage = DocumentTypeNames(\n",
    "        controlBasePath=controlBasePath,\n",
    "        fileNameDocumentTypeNames=fileNameDocumentTypeNames,\n",
    "        languageCode=languageCode,\n",
    "        domain=domain,\n",
    "        procedureType=procedureType,\n",
    "        documentNumber=documentNumber\n",
    "        ).extractStopWordLanguage()\n",
    "    \n",
    "    ###########  END   ################\n",
    "\n",
    "    ###################################\n",
    "    #########  STEP 5 #################\n",
    "    \n",
    "    \n",
    "    matchDocObj = MatchDocument(\n",
    "        logger,\n",
    "        controlBasePath,\n",
    "        basePath,\n",
    "        domain,\n",
    "        procedureType,\n",
    "        languageCode,\n",
    "        documentNumber,\n",
    "        fileNameDoc,\n",
    "        fileNameQrd,\n",
    "        fileNameMatchRuleBook,\n",
    "        fileNameDocumentTypeNames,\n",
    "        topHeadingsConsidered,\n",
    "        bottomHeadingsConsidered,\n",
    "        stopWordFilterLen,\n",
    "        stopWordlanguage,\n",
    "        isPackageLeaflet,\n",
    "        medName)\n",
    "    df, coll, documentType, documentTypeForUI = matchDocObj.matchHtmlHeaddingsWithQrd()\n",
    "    \n",
    "    ###########  END   ################\n",
    "\n",
    "    return df, coll, documentType, documentTypeForUI\n",
    "\n",
    "def parseDocument(controlBasePath,\n",
    "                  basePath,\n",
    "                  htmlDocName,\n",
    "                  fileNameQrd,\n",
    "                  fileNameMatchRuleBook,\n",
    "                  fileNameDocumentTypeNames,\n",
    "                  jsonTempFileName,\n",
    "                  listBundleDocumentTypeCodesFileName,\n",
    "                  apiMmgtBaseUrl,\n",
    "                  getListApiEndPointUrlSuffix,\n",
    "                  addUpdateListApiEndPointUrlSuffix,\n",
    "                  addBundleApiEndPointUrlSuffix,\n",
    "                  sporApiMgmtApiBaseUrl,\n",
    "                  pmsApiEndpointSuffix, \n",
    "                  smsApiEndpointSuffix,\n",
    "                  localCredsJson,\n",
    "                  medName = None,\n",
    "                  NAPDocumentNumber=None):\n",
    "    \n",
    "    listRegulatedAuthCodesAccrossePI = []\n",
    "    \n",
    "    if \"/\" in basePath:\n",
    "        pathSep = \"/\"        \n",
    "    else:\n",
    "        pathSep = \"\\\\\"\n",
    "    \n",
    "    fileNameLog = os.path.join(basePath,'FinalLog.txt')\n",
    "\n",
    "    pathComponents = basePath.split(pathSep)\n",
    "    print(pathComponents, htmlDocName)\n",
    "    timestamp = pathComponents[-1]\n",
    "    languageCode =  pathComponents[-2]\n",
    "    medName = pathComponents[-3]\n",
    "    procedureType = pathComponents[-4]\n",
    "    domain = pathComponents[-5]\n",
    "\n",
    "    print(timestamp, languageCode, medName, procedureType, domain)\n",
    "        \n",
    "    flowLogger =  MatchLogger(f\"Flow Logger HTML_{getRandomString(1)}\", htmlDocName, domain, procedureType, languageCode, \"HTML\", fileNameLog)\n",
    "    \n",
    "    metrics = Metrics(os.path.join(basePath,'Metrics.csv'),flowLogger)\n",
    "    \n",
    "    \n",
    "    flowLogger.logFlowCheckpoint(\"Starting HTML Conversion To Json\")\n",
    "    ###Convert Html to Json\n",
    "    \n",
    "    ###################################\n",
    "    #### Perform Steps 2&3 ############\n",
    "    \n",
    "    \n",
    "    fileNameJson, stylesFilePath = convertHtmlToJson(controlBasePath, basePath, domain, procedureType, languageCode, htmlDocName, fileNameQrd, fileNameLog, NAPDocumentNumber)\n",
    "    \n",
    "    #############  END ################\n",
    "    print(\"stylePath:-\",stylesFilePath)\n",
    "    flowLogger.logFlowCheckpoint(\"Completed HTML Conversion To Json\")\n",
    "    metrics.getMetric(\"HTML Conversion To Json\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if procedureType == \"CAP\":\n",
    "        \n",
    "        ###################################\n",
    "        ### OPTIONAL STEP Split Json ######\n",
    "        \n",
    "        \n",
    "        flowLogger.logFlowCheckpoint(\"Starting Json Split\")\n",
    "\n",
    "        ###Split Uber Json to multiple Jsons for each category.\n",
    "        partitionedJsonPaths = splitJson(controlBasePath, basePath, domain, procedureType, languageCode, fileNameJson, fileNameQrd, fileNameLog)\n",
    "\n",
    "        partitionedJsonPaths = [ path.split(pathSep)[-1] for path in partitionedJsonPaths]\n",
    "        flowLogger.logFlowCheckpoint(str(partitionedJsonPaths))\n",
    "\n",
    "        flowLogger.logFlowCheckpoint(\"Completed Json Split\")\n",
    "        metrics.getMetric(\"Split Json\")\n",
    "        #############  END ################\n",
    "        flowLogger.logFlowCheckpoint(\"Started Processing CAP Partitioned Jsons\")\n",
    "        \n",
    "    else:       \n",
    "\n",
    "        # Create the partitioned json for NAP which will be the same as output json as there is only one document.\n",
    "\n",
    "        with open(os.path.join(basePath,'outputJSON',fileNameJson)) as f:\n",
    "            json_html = json.load(f)\n",
    "        dfPartitioned = pd.DataFrame(json_html['data'])\n",
    "\n",
    "        if(not os.path.exists(os.path.join(basePath, 'partitionedJSONs'))):\n",
    "            os.mkdir(os.path.join(basePath, 'partitionedJSONs'))\n",
    "\n",
    "        dfPartitioned.to_json(os.path.join(basePath, 'partitionedJSONs', fileNameJson), orient ='records')\n",
    "        partitionedJsonPaths = [fileNameJson]\n",
    "        flowLogger.logFlowCheckpoint(\"Started Processing NAP Json\")\n",
    "        \n",
    "    \n",
    "    previous_pms_oms_annotation_data  = None\n",
    "    for index, fileNamePartitioned in enumerate(partitionedJsonPaths):\n",
    "        print(\"Index\", index)\n",
    "        #if index in [0,1]:\n",
    "        #    continue\n",
    "        if procedureType != \"CAP\":\n",
    "            index = int(NAPDocumentNumber)\n",
    "        flowLogger.logFlowCheckpoint(f\"\\n\\n\\n\\n||||||||||||||||||||||||||||||||{str(index)} ||||| {str(fileNamePartitioned)}||||||||||||||||||||||||||||||||\\n\\n\\n\\n\")\n",
    "        \n",
    "        if index == 3:\n",
    "            stopWordFilterLen = 100\n",
    "            isPackageLeaflet = True\n",
    "        else:\n",
    "            stopWordFilterLen = 6\n",
    "            isPackageLeaflet = False\n",
    "        \n",
    "        ###################################\n",
    "        #### Perform Steps 4&5 ############\n",
    "        \n",
    "        df, coll, documentType, documentTypeForUI = extractAndValidateHeadings(controlBasePath,\n",
    "                                    basePath,\n",
    "                                    domain,\n",
    "                                    procedureType,\n",
    "                                    languageCode,\n",
    "                                    index,\n",
    "                                    fileNamePartitioned,\n",
    "                                    fileNameQrd,\n",
    "                                    fileNameMatchRuleBook,\n",
    "                                    fileNameDocumentTypeNames,\n",
    "                                    fileNameLog,\n",
    "                                    stopWordFilterLen=stopWordFilterLen,\n",
    "                                    isPackageLeaflet=isPackageLeaflet,\n",
    "                                    medName=medName)\n",
    "        #return df, coll, documentType, documentTypeForUI\n",
    "        print(f\"Completed Heading Extraction For File\")\n",
    "        flowLogger.logFlowCheckpoint(\"Completed Heading Extraction For File\")\n",
    "        metrics.getMetric(f\"{index}: Heading Extraction\")\n",
    "        ############# END #################\n",
    "\n",
    "        \n",
    "        ###################################\n",
    "        #########  STEP 6 START ###########\n",
    "    \n",
    "        print(f\"Starting Document Annotation For File :- {fileNamePartitioned}\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Starting Document Annotation For File\")\n",
    "        documentAnnotationObj = DocumentAnnotation(fileNamePartitioned,\n",
    "                                                   localCredsJson['PmsSubscriptionKey'],\n",
    "                                                   localCredsJson['SmsSubscriptionKey'],\n",
    "                                                   sporApiMgmtApiBaseUrl,\n",
    "                                                   pmsApiEndpointSuffix,\n",
    "                                                   smsApiEndpointSuffix,\n",
    "                                                   df,\n",
    "                                                   coll,\n",
    "                                                   domain,\n",
    "                                                   procedureType,\n",
    "                                                   index)\n",
    "        \n",
    "        pms_oms_annotation_data = documentAnnotationObj.processRegulatedAuthorizationForDoc()\n",
    "        print(pms_oms_annotation_data)\n",
    "        \n",
    "        if pms_oms_annotation_data == None:\n",
    "            pms_oms_annotation_data = previous_pms_oms_annotation_data\n",
    "        else:\n",
    "            previous_pms_oms_annotation_data = pms_oms_annotation_data\n",
    "        \n",
    "       \n",
    "        \n",
    "        print(f\"Completed Document Annotation\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Completed Document Annotation\")\n",
    "        metrics.getMetric(f\"{index}: Document Annotation\")\n",
    "        #############  END ################\n",
    "        \n",
    "        ###################################\n",
    "        #########  STEP 7 START ###########\n",
    "        print(f\"Starting Extracting Content Between Heading For File :- {fileNamePartitioned}\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Starting Extracting Content Between Heading\")\n",
    "        \n",
    "        extractContentlogger =  MatchLogger(f'ExtractContentBetween_{index}_{getRandomString(1)}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "        extractorObj = DataBetweenHeadingsExtractor(extractContentlogger, basePath, coll)\n",
    "        dfExtractedHierRR = extractorObj.extractContentBetweenHeadings(fileNamePartitioned)\n",
    "        \n",
    "        print(f\"Completed Extracting Content Between Heading\")        \n",
    "        flowLogger.logFlowCheckpoint(\"Completed Extracting Content Between Heading\")\n",
    "        metrics.getMetric(f\"{index}: Content Extraction\")\n",
    "        \n",
    "        ########### END ###################\n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        #########  STEP 8 START ###########\n",
    "        \n",
    "        listBundleDocumentTypeCodesFilePath = os.path.join(controlBasePath,\n",
    "                                                                listBundleDocumentTypeCodesFileName.split(\".\")[0],\n",
    "                                                                listBundleDocumentTypeCodesFileName)\n",
    "        with open(listBundleDocumentTypeCodesFilePath, encoding='utf-8') as f:\n",
    "            listBundleDocumentTypeCodes = json.load(f)\n",
    "            \n",
    "        bundleDocumentTypeCode = listBundleDocumentTypeCodes[domain][str(index)]['listBundleCode']\n",
    "        bundleMetaData = {'pmsOmsAnnotationData':pms_oms_annotation_data,\n",
    "                          'documentTypeCode': bundleDocumentTypeCode,\n",
    "                          'documentType': documentTypeForUI,\n",
    "                          'languageCode': languageCode,\n",
    "                          'medName': medName}\n",
    "        \n",
    "        \n",
    "        ############# END #################\n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        #########  STEP 9 START ###########\n",
    "        \n",
    "        xmlLogger =  MatchLogger(f'XmlGeneration_{index}_{getRandomString(1)}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "        \n",
    "        fhirXmlGeneratorObj = FhirXmlGenerator(xmlLogger, controlBasePath, basePath, bundleMetaData, stylesFilePath)\n",
    "        fileNameXml = fileNamePartitioned.replace('.json','.xml')\n",
    "        generatedXml = fhirXmlGeneratorObj.generateXml(dfExtractedHierRR, fileNameXml)\n",
    "        \n",
    "        metrics.getMetric(f\"{index}: Generate XML\")\n",
    "        \n",
    "        ########### END ###################\n",
    "        \n",
    "        ###################################\n",
    "        #########  STEP 10 START ##########\n",
    "        \n",
    "        fhirServiceLogger =  MatchLogger(f'XML Submission Logger_{index}_{getRandomString(1)}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "        \n",
    "        fhirServiceObj = FhirService(fhirServiceLogger, apiMmgtBaseUrl, addBundleApiEndPointUrlSuffix, localCredsJson['apiMmgtSubsKey'], basePath, generatedXml)\n",
    "        fhirServiceObj.submitFhirXml()\n",
    "        \n",
    "        metrics.getMetric(f\"{index}: Submit FHIR Msg\")\n",
    "        \n",
    "        print(f\"Created XML File For :- {fileNamePartitioned}\")\n",
    "        \n",
    "        ############## END ################\n",
    "        \n",
    "        ###################################\n",
    "        #########  STEP 11 START ##########\n",
    "        flowLogger.logFlowCheckpoint(\"Starting list bundle update/addition\")\n",
    "        if documentAnnotationObj.listRegulatedAuthorizationIdentifiers != None:\n",
    "            for id in documentAnnotationObj.listRegulatedAuthorizationIdentifiers:\n",
    "                listRegulatedAuthCodesAccrossePI.append(id)\n",
    "        listBundleLogger =  MatchLogger(f'List Bundle Creation Logger_{index}_{getRandomString(1)}', fileNamePartitioned, domain, procedureType, languageCode, index, fileNameLog)\n",
    "        print(\"\\nlistRegulatedAuthCodesAccrossePI\",listRegulatedAuthCodesAccrossePI)\n",
    "        try:\n",
    "            listBundleHandler = ListBundleHandler(listBundleLogger,\n",
    "                     domain,\n",
    "                     procedureType,\n",
    "                     index,\n",
    "                     documentType,\n",
    "                     documentTypeForUI,\n",
    "                     languageCode,\n",
    "                     medName,\n",
    "                     controlBasePath,\n",
    "                     jsonTempFileName,\n",
    "                     listBundleDocumentTypeCodesFileName,\n",
    "                     fileNameDocumentTypeNames,\n",
    "                     listRegulatedAuthCodesAccrossePI,\n",
    "                     apiMmgtBaseUrl,\n",
    "                     getListApiEndPointUrlSuffix,\n",
    "                     addUpdateListApiEndPointUrlSuffix,\n",
    "                     localCredsJson['apiMmgtSubsKey'])\n",
    "\n",
    "            listBundleXml = listBundleHandler.addOrUpdateDocumentItem(str(fhirServiceObj.SubmittedFhirMsgRefId), pms_oms_annotation_data)\n",
    "            print(listBundleXml)\n",
    "            listBundleHandler.submitListXmLToServer(listBundleXml)\n",
    "\n",
    "            flowLogger.logFlowCheckpoint(\"Completed list bundle update/addition\")\n",
    "            metrics.getMetric(f\"{index}: Update/Add List Bundle\")\n",
    "                    #return df,coll,dfExtractedHierRR\n",
    "                \n",
    "        ################ END #############\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            if 'No MAN Code found' in str(e):\n",
    "                flowLogger.logFlowCheckpoint(\"Skipping list bundle addtion/update as no MAN found\")\n",
    "            \n",
    "    \n",
    "    flowLogger.logFlowCheckpoint(\"Completed Processing Partitioned Jsons\")\n",
    "    metrics.getMetric(f\"{index}: Completed\")\n",
    "    metrics.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "######### Perform All Steps #########\n",
    "def runAll(inputList):\n",
    "    for inputDoc in inputList:\n",
    "        # inputZipFolderPath = \"F:\\Projects\\EMA\\Repository\\EMA EPI PoC\\\\function_code\\\\inputblob\"\n",
    "        inputZipFolderPath = os.path.abspath(os.path.join('..'))\n",
    "        inputZipFolderPath = os.path.join(inputZipFolderPath, 'inputblob')\n",
    "        inputZipFileName = inputDoc\n",
    "\n",
    "        fileNameQrd = 'qrd_canonical_model.csv'\n",
    "        fileNameMatchRuleBook = 'ruleDict.json'\n",
    "        fileNameLocalCreds = \"localCredentialsDev.json\"\n",
    "        fileNameDocumentTypeNames = 'documentTypeNames.json'\n",
    "        fsMountName = '/mounted'\n",
    "        jsonTempFileName = 'listBundleJsonTemplate.json'\n",
    "        listBundleDocumentTypeCodesFileName = 'listBundleDocumentTypeCodes.json'\n",
    "        apiMmgtBaseUrl = \"https://ema-dap-epi-dev-fhir-apim.azure-api.net\"\n",
    "        getListApiEndPointUrlSuffix = \"/epi/v1/List\"\n",
    "        addUpdateListApiEndPointUrlSuffix = \"/epi-w/v1/List\"\n",
    "        addBundleApiEndPointUrlSuffix = \"/epi-w/v1/Bundle\"\n",
    "        \n",
    "        sporApiMgmtApiBaseUrl = \"https://spor-sit.azure-api.net\"\n",
    "        pmsApiEndpointSuffix = \"/pms/api/v2/\"\n",
    "        smsApiEndpointSuffix = \"/sms/api/v2/\"\n",
    "                \n",
    "        info = inputZipFileName.split(\"~\")\n",
    "        ###################################\n",
    "        ########  STEP 1 START ############\n",
    "        ###################################\n",
    "        try:\n",
    "            medName = info[0]\n",
    "            domain = info[1]\n",
    "            procedureType = info[2]\n",
    "            languageCode = info[3]\n",
    "            if procedureType == \"NAP\":     \n",
    "                NAPDocumentNumber = info[4]\n",
    "                timestamp = info[5]\n",
    "            else:\n",
    "                timestamp = info[4]\n",
    "                NAPDocumentNumber = None\n",
    "                \n",
    "            timestamp = timestamp.replace(\".zip\",\"\")\n",
    "\n",
    "        except Exception:\n",
    "            raise f\"Missing required info in the zip file name {inputZipFileName}\"\n",
    "\n",
    "        if \"\\\\\" in os.getcwd():\n",
    "            localEnv = True\n",
    "            inputZipFolderPath = os.path.join(os.path.abspath(os.path.join('..')),inputZipFolderPath)\n",
    "            if os.path.exists(os.path.join(os.path.abspath(os.path.join('..')), 'work')):\n",
    "                outputFolderPath = os.path.join(os.path.abspath(os.path.join('..')), 'work', f\"{domain}\", f\"{procedureType}\", f\"{medName}\", f\"{languageCode}\", f\"{timestamp}\")\n",
    "            elif os.path.exists(os.path.join(os.path.abspath(os.path.join('../..')), 'work')):\n",
    "                outputFolderPath = os.path.join(os.path.abspath(os.path.join('../..')), 'work', f\"{domain}\", f\"{procedureType}\", f\"{medName}\", f\"{languageCode}\", f\"{timestamp}\")\n",
    "\n",
    "            if os.path.exists(os.path.join(os.path.abspath(os.path.join(\"..\")),'control')):\n",
    "                controlFolderPath = os.path.join(os.path.abspath(os.path.join('..')),'control')\n",
    "            elif os.path.exists(os.path.join(os.path.abspath(os.path.join(\"../..\")),'control')):\n",
    "                controlFolderPath = os.path.join(os.path.abspath(os.path.join('../..')),'control')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            localEnv = False\n",
    "            inputZipFolderPath = os.path.join(f'{fsMountName}',inputZipFolderPath)\n",
    "            outputFolderPath = os.path.join(f'{fsMountName}', 'work', f\"{domain}\", f\"{procedureType}\", f\"{medName}\", f\"{languageCode}\", f\"{timestamp}\")\n",
    "            controlFolderPath = os.path.join(f'{fsMountName}','control')\n",
    "\n",
    "        localCredFilePath = os.path.join(controlFolderPath, 'localCredentials', fileNameLocalCreds)\n",
    "        \n",
    "        with open(localCredFilePath) as r:\n",
    "            localCredsJson = json.load(r)\n",
    "        \n",
    "        metaDatakeys = set([ key for key in localCredsJson])\n",
    "        requiredCredsParameters = set(['PmsSubscriptionKey','SmsSubscriptionKey','apiMmgtSubsKey','appInsightsInstrumentationKey'])\n",
    "        \n",
    "        if len(requiredCredsParameters - metaDatakeys) !=0:\n",
    "            raise Exception(f\"Missing required keys in local creds file :- {str(requiredCredsParameters-metaDatakeys)}\")\n",
    "        \n",
    "        for key in localCredsJson:\n",
    "            if len(localCredsJson[key]) == 0 or localCredsJson[key] == None:\n",
    "                raise Exception(f\"Missing required info in the zip file for key {key}\")\n",
    "        \n",
    "        os.environ['APPLICATIONINSIGHTS_CONNECTION_STRING'] = localCredsJson['appInsightsInstrumentationKey']\n",
    "        \n",
    "        print(inputZipFileName, inputZipFolderPath, outputFolderPath, controlFolderPath)\n",
    "\n",
    "        mode = 0o666\n",
    "\n",
    "        if localEnv is True:\n",
    "            inputZipFolderPath = inputZipFolderPath.replace(\"/\",\"\\\\\")\n",
    "            outputFolderPath = outputFolderPath.replace(\"/\",\"\\\\\")\n",
    "            controlFolderPath = controlFolderPath.replace(\"/\",\"\\\\\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(inputZipFolderPath, mode)\n",
    "            os.makedirs(outputFolderPath, mode)\n",
    "            os.makedirs(controlFolderPath, mode)\n",
    "\n",
    "        except Exception:\n",
    "            print(\"Already Present\")\n",
    "\n",
    "        with zipfile.ZipFile(f'{inputZipFolderPath}/{inputZipFileName}',\"r\") as zip_ref:\n",
    "                zip_ref.extractall(outputFolderPath)\n",
    "\n",
    "\n",
    "        _,_,fileNames = next(os.walk(outputFolderPath))\n",
    "        htmlFileName = [fileName for fileName in fileNames if \".htm\" in fileName][0]\n",
    "\n",
    "        print(htmlFileName)\n",
    "\n",
    "        ############### END ###############\n",
    "        \n",
    "        ####################################\n",
    "        ####### Perform Steps #2-11 ########\n",
    "        parseDocument(controlFolderPath,\n",
    "                  outputFolderPath,\n",
    "                  htmlFileName,\n",
    "                  fileNameQrd,\n",
    "                  fileNameMatchRuleBook,\n",
    "                  fileNameDocumentTypeNames,\n",
    "                  jsonTempFileName,\n",
    "                  listBundleDocumentTypeCodesFileName,\n",
    "                  apiMmgtBaseUrl,\n",
    "                  getListApiEndPointUrlSuffix,\n",
    "                  addUpdateListApiEndPointUrlSuffix,\n",
    "                  addBundleApiEndPointUrlSuffix,\n",
    "                  sporApiMgmtApiBaseUrl,\n",
    "                  pmsApiEndpointSuffix, \n",
    "                  smsApiEndpointSuffix,\n",
    "                  localCredsJson,\n",
    "                  medName,\n",
    "                  NAPDocumentNumber)\n",
    "        ############ END ##################\n",
    "\n",
    "        \n",
    "##########  END ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAllTest(inputList):\n",
    "    for inputDoc in inputList:\n",
    "        # inputZipFolderPath = \"F:\\Projects\\EMA\\Repository\\EMA EPI PoC\\\\function_code\\\\inputblob\"\n",
    "        inputZipFolderPath = os.path.abspath(os.path.join('..'))\n",
    "        inputZipFolderPath = os.path.join(inputZipFolderPath, 'inputblob')\n",
    "        inputZipFileName = inputDoc\n",
    "\n",
    "        fileNameQrd = 'qrd_canonical_model.csv'\n",
    "        fileNameMatchRuleBook = 'ruleDict.json'\n",
    "        fileNameLocalCreds = \"localCredentialsTest.json\"\n",
    "        fileNameDocumentTypeNames = 'documentTypeNames.json'\n",
    "        fsMountName = '/mounted'\n",
    "        jsonTempFileName = 'listBundleJsonTemplate.json'\n",
    "        listBundleDocumentTypeCodesFileName = 'listBundleDocumentTypeCodes.json'\n",
    "        apiMmgtBaseUrl = \"https://ema-dap-epi-tst-fhir-apim.azure-api.net\"\n",
    "        getListApiEndPointUrlSuffix = \"/epi/v1/List\"\n",
    "        addUpdateListApiEndPointUrlSuffix = \"/epi-w/v1/List\"\n",
    "        addBundleApiEndPointUrlSuffix = \"/epi-w/v1/Bundle\"\n",
    "        \n",
    "        sporApiMgmtApiBaseUrl = \"https://spor-sit.azure-api.net\"\n",
    "        pmsApiEndpointSuffix = \"/pms/api/v2/\"\n",
    "        smsApiEndpointSuffix = \"/sms/api/v2/\"\n",
    "                \n",
    "\n",
    "        info = inputZipFileName.split(\"~\")\n",
    "\n",
    "        try:\n",
    "            medName = info[0]\n",
    "            domain = info[1]\n",
    "            procedureType = info[2]\n",
    "            languageCode = info[3]\n",
    "            if procedureType == \"NAP\":     \n",
    "                NAPDocumentNumber = info[4]\n",
    "                timestamp = info[5]\n",
    "            else:\n",
    "                timestamp = info[4]\n",
    "                NAPDocumentNumber = None\n",
    "                \n",
    "            timestamp = timestamp.replace(\".zip\",\"\")\n",
    "\n",
    "        except Exception:\n",
    "            raise f\"Missing required info in the zip file name {inputZipFileName}\"\n",
    "\n",
    "        if \"\\\\\" in os.getcwd():\n",
    "            localEnv = True\n",
    "            inputZipFolderPath = os.path.join(os.path.abspath(os.path.join('..')),inputZipFolderPath)\n",
    "            outputFolderPath = os.path.join(os.path.abspath(os.path.join('..')), 'work', f\"{domain}\", f\"{procedureType}\", f\"{medName}\", f\"{languageCode}\", f\"{timestamp}\")\n",
    "            controlFolderPath = os.path.join(os.path.abspath(os.path.join('..')),'control')\n",
    "        else:\n",
    "            localEnv = False\n",
    "            inputZipFolderPath = os.path.join(f'{fsMountName}',inputZipFolderPath)\n",
    "            outputFolderPath = os.path.join(f'{fsMountName}', 'work', f\"{domain}\", f\"{procedureType}\", f\"{medName}\", f\"{languageCode}\", f\"{timestamp}\")\n",
    "            controlFolderPath = os.path.join(f'{fsMountName}','control')\n",
    "\n",
    "        localCredFilePath = os.path.join(controlFolderPath, 'localCredentials', fileNameLocalCreds)\n",
    "        \n",
    "        with open(localCredFilePath) as r:\n",
    "            localCredsJson = json.load(r)\n",
    "        \n",
    "        metaDatakeys = set([ key for key in localCredsJson])\n",
    "        requiredCredsParameters = set(['PmsSubscriptionKey','SmsSubscriptionKey','apiMmgtSubsKey','appInsightsInstrumentationKey'])\n",
    "        \n",
    "        if len(requiredCredsParameters - metaDatakeys) !=0:\n",
    "            raise Exception(f\"Missing required keys in local creds file :- {str(requiredCredsParameters-metaDatakeys)}\")\n",
    "        \n",
    "        for key in localCredsJson:\n",
    "            if len(localCredsJson[key]) == 0 or localCredsJson[key] == None:\n",
    "                raise Exception(f\"Missing required info in the zip file for key {key}\")\n",
    "        \n",
    "        os.environ['APPLICATIONINSIGHTS_CONNECTION_STRING'] = localCredsJson['appInsightsInstrumentationKey']\n",
    "        \n",
    "        print(inputZipFileName, inputZipFolderPath, outputFolderPath, controlFolderPath)\n",
    "\n",
    "        mode = 0o666\n",
    "\n",
    "        if localEnv is True:\n",
    "            inputZipFolderPath = inputZipFolderPath.replace(\"/\",\"\\\\\")\n",
    "            outputFolderPath = outputFolderPath.replace(\"/\",\"\\\\\")\n",
    "            controlFolderPath = controlFolderPath.replace(\"/\",\"\\\\\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(inputZipFolderPath, mode)\n",
    "            os.makedirs(outputFolderPath, mode)\n",
    "            os.makedirs(controlFolderPath, mode)\n",
    "\n",
    "        except Exception:\n",
    "            print(\"Already Present\")\n",
    "\n",
    "        with zipfile.ZipFile(f'{inputZipFolderPath}/{inputZipFileName}',\"r\") as zip_ref:\n",
    "                zip_ref.extractall(outputFolderPath)\n",
    "\n",
    "\n",
    "        _,_,fileNames = next(os.walk(outputFolderPath))\n",
    "        htmlFileName = [fileName for fileName in fileNames if \".htm\" in fileName][0]\n",
    "\n",
    "        print(htmlFileName)\n",
    "\n",
    "        parseDocument(controlFolderPath,\n",
    "                  outputFolderPath,\n",
    "                  htmlFileName,\n",
    "                  fileNameQrd,\n",
    "                  fileNameMatchRuleBook,\n",
    "                  fileNameDocumentTypeNames,\n",
    "                  jsonTempFileName,\n",
    "                  listBundleDocumentTypeCodesFileName,\n",
    "                  apiMmgtBaseUrl,\n",
    "                  getListApiEndPointUrlSuffix,\n",
    "                  addUpdateListApiEndPointUrlSuffix,\n",
    "                  addBundleApiEndPointUrlSuffix,\n",
    "                  sporApiMgmtApiBaseUrl,\n",
    "                  pmsApiEndpointSuffix, \n",
    "                  smsApiEndpointSuffix,\n",
    "                  localCredsJson,\n",
    "                  medName,\n",
    "                  NAPDocumentNumber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mounted/control/localCredentials/localCredentialsDev.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/np/m991xnfd1wb_6vs6c4png9sh0000gn/T/ipykernel_36251/2018994971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abacavir Accord~H~NAP~sv~0~2021-05-27T10-49-42Z.zip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/np/m991xnfd1wb_6vs6c4png9sh0000gn/T/ipykernel_36251/171072704.py\u001b[0m in \u001b[0;36mrunAll\u001b[0;34m(inputList)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mlocalCredFilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrolFolderPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'localCredentials'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileNameLocalCreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocalCredFilePath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mlocalCredsJson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mounted/control/localCredentials/localCredentialsDev.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "runAll(['Abacavir Accord~H~NAP~sv~0~2021-05-27T10-49-42Z.zip'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllTest(['Cystagon~H~CAP~no~2021-06-25T14-03-22Z.zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllTest(['Cystagon~H~CAP~no~2021-06-25T14-03-22Z.zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllTest(['Metacam~V~CAP~en~2021-05-17T11-36-04Z.zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputList = ['ELOCTA~H~CAP~bg~2021-06-09T08-18-48Z.zip',\n",
    " 'ELOCTA~H~CAP~cs~2021-06-09T09-32-50Z.zip',\n",
    " 'ELOCTA~H~CAP~da~2021-06-09T09-34-52Z.zip',\n",
    " 'ELOCTA~H~CAP~de~2021-06-09T09-36-33Z.zip',\n",
    " 'ELOCTA~H~CAP~el~2021-06-07T06-03-45Z.zip']\n",
    "\n",
    "runAll(inputList)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3493284b5b576f7787eb042e6d217ba74ce0a29b2f909c49611816a9e70da287"
  },
  "kernelspec": {
   "display_name": "Python 3.8 EMA ePI PoC",
   "language": "python",
   "name": "p38-ema-epi-poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
